{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acrisvall/recipes_rag/.venv/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAI\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Set Pinecone Key and Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Create Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'recipes-index'\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# We create a new index with a dimension size of 1536 (for text-embedding-ada-002)\n",
    "pc.create_index(\n",
    "    index_name,\n",
    "    dimension=1536,  # dimensionality of text-embedding-ada-002\n",
    "    metric='cosine',\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    ")\n",
    "\n",
    "# Wait for the index to be initialized\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = (\n",
    "    'Title: ' + data['title'] + ', ' +\n",
    "    'Description: ' + data['description'] + ', ' +\n",
    "    'Ingredients: ' + data['ingredients'] + ', ' +\n",
    "    'Prep time: ' + data['prep_time'] + ', ' +\n",
    "    'Cook time: ' + data['cook_time'] + ', ' +\n",
    "    'Calories: ' + data['kcal'].astype(str) + ' kcal, ' +\n",
    "    'Fat: ' + data['fat'].astype(str) + ' g, ' +\n",
    "    'Saturates: ' + data['saturates'].astype(str) + ' g, ' +\n",
    "    'Carbs: ' + data['carbs'].astype(str) + ' g, ' +\n",
    "    'Sugars: ' + data['sugars'].astype(str) + ' g, ' +\n",
    "    'Fibre: ' + data['fibre'].astype(str) + ' g, ' +\n",
    "    'Protein: ' + data['protein'].astype(str) + ' g, ' +\n",
    "    'Salt: ' + data['salt'].astype(str) + ' g'\n",
    ")\n",
    "\n",
    "texts_list = texts.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 Open AI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-3-small\"\n",
    "embeddings_model = OpenAIEmbeddings(model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 Create Open Ai embeddings for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = []\n",
    "for text in texts_list:\n",
    "  response = embeddings_model.embed_query(text)\n",
    "  embeddings.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106\n"
     ]
    }
   ],
   "source": [
    "embeddings[:5]\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 Upsert the Data to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1106 recipes to Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Upsert the Data to Pinecone\n",
    "for i, embedding_vector in enumerate(embeddings):\n",
    "    metadata = {\n",
    "        \"id\": str(i),\n",
    "        \"title\": data.loc[i, 'title'],\n",
    "        \"description\": data.loc[i, 'description'],\n",
    "        \"prep_time\": data.loc[i, 'prep_time'],\n",
    "        \"cook_time\": data.loc[i, 'cook_time'],\n",
    "        \"difficulty\": data.loc[i, 'difficulty'],\n",
    "        \"serves\": data.loc[i, 'serves'],\n",
    "        \"diet_type\": data.loc[i, 'diet_type'],\n",
    "        \"ingredients\": data.loc[i, 'ingredients'],\n",
    "        \"calories\": data.loc[i, 'kcal'],\n",
    "        \"fat\": data.loc[i, 'fat'],\n",
    "        \"saturates\": data.loc[i, 'saturates'],\n",
    "        \"carbs\": data.loc[i, 'carbs'],\n",
    "        \"sugars\": data.loc[i, 'sugars'],\n",
    "        \"fibre\": data.loc[i, 'fibre'],\n",
    "        \"protein\": data.loc[i, 'protein'],\n",
    "        \"salt\": data.loc[i, 'salt'],\n",
    "        \"instructions\": data.loc[i, 'instructions'],\n",
    "    }\n",
    "    index.upsert(vectors=[(str(i), embedding_vector, metadata)])\n",
    "\n",
    "print(f\"Uploaded {len(embeddings)} recipes to Pinecone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 Query Pinecone with a new recipe query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m embeddings_model\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Retrieve relevant contexts from Pinecone\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m query_res \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39mquery(vector\u001b[38;5;241m=\u001b[39mquery_vector, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(query_res)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(query_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "# query = \"please a recipe that can be prepare in less than 20 min\"\n",
    "query = \"please a dessert and a salad recommendation\"\n",
    "# create the query vector\n",
    "query_vector = embeddings_model.embed_query(query)\n",
    "\n",
    "# Retrieve relevant contexts from Pinecone\n",
    "query_res = index.query(vector=query_vector, top_k=3, include_metadata=True)\n",
    "print(query_res)\n",
    "print(len(query_res[\"matches\"]))\n",
    "\n",
    "# Extract the matched metadata (recipes) from Pinecone results\n",
    "contexts = [item['metadata'] for item in query_res['matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rose & pomegranate jellies with cardamom panna cotta\n",
      "Preparation Time: 30 mins\n",
      "Cooking Time: 15 mins\n",
      "Difficulty: More effort\n",
      "Serves: Serves 6\n",
      "Diet Type: Gluten-free\n",
      "Description: This dessert combo is wonderfully refreshing, with the garnet-coloured, tart jelly cutting through the creaminess of the cardamom panna cotta base\n",
      "Ingredients: 7gelatine leaves, 1 tsplemon juice, 100gcaster sugar, 250mlunsweetened pomegranate juice, 1 tsprosewater, 1pomegranate, seeds only, 300mldouble cream, 200mlwhole milk, 6cardamom pods, seeds lightly bashed, 1vanilla pod, split, 2½gelatine leaves, 75gcaster sugar, For the panna cotta, 300mldouble cream, 200mlwhole milk, 6cardamom pods, seeds lightly bashed, 1vanilla pod, split, 2½gelatine leaves, 75gcaster sugar\n",
      "Instructions: First, make the jelly. Soak the gelatine in cold water for 10 mins. Bring the lemon juice and 300ml water to the boil over a medium heat. Stir in the sugar until dissolved, then remove from the heat. Squeeze the excess water from the gelatine, then stir it into the syrup to dissolve. Stir in the pomegranate juice and rosewater. Take off the heat and leave to cool. Meanwhile, divide the pomegranate seeds between six 200ml moulds. When the jelly is at room temperature, divide between the moulds. Chill for 2 hrs. While the jelly chills, make the panna cotta. Pour the cream and milk into a pan, add the cardamom and vanilla and warm over a low heat, stirring. Turn up the heat, bring to a simmer and cook until it has reduced by a third, 8-10 mins. (Don’t let it boil.) Put the gelatine in a bowl, cover with water and leave to soak for 10 mins. Squeeze the water out, add the gelatine to the cream mix along with the sugar and stir to dissolve. Cool slightly, strain into a jug, pour over the jelly and chill for 6 hrs or overnight to set.Will keep chilled for a day. Serve cold. \n",
      "\n",
      "---\n",
      "\n",
      "Title: Bakewell pudding\n",
      "Preparation Time: 30 mins\n",
      "Cooking Time: 50 mins\n",
      "Difficulty: Easy\n",
      "Serves: Serves 8\n",
      "Diet Type: Freezable\n",
      "Description: For a warm and cosy alternative to the bakewell tart, try making this egg-based pud. It's best served with cream or ice cream\n",
      "Ingredients: 320g sheetready-rolled all-butter puff pastry, 150gbutter, softened, 150gcaster sugar, 3eggs, 150gground almonds, 1lemon, zested, 1 tspalmond extract, 3 tbspraspberry jam, 25gflaked almonds, 1 tbspicing sugar\n",
      "Instructions: Unravel the pastry and use it to line a 20cm cake or pie tin with sloped sides. Trim the pastry, leaving about 2cm overhanging. Chill the pastry case while you prepare the filling. Heat the oven to 180C/160C fan/gas 4. Beat the butter and sugar together in a bowl using an electric whisk for 2-3 mins until smooth and creamy. Add the eggs, ground almonds, lemon zest, almond extract and a pinch of salt, then beat again until combined. Remove the pastry case from the fridge and spread the jam over its base, then spoon in the almond and egg mixture, smoothing it to the edge using a spatula. Scatter the flaked almonds on top and bake for 50 mins until golden brown. Leave to cool for at least 30 mins, then dust with icing sugar and serve with cream or ice cream.Will keep in an airtight container for a few days. \n",
      "\n",
      "---\n",
      "\n",
      "Title: Charred & smoky peach sundae\n",
      "Preparation Time: 10 mins\n",
      "Cooking Time: 10 mins\n",
      "Difficulty: Easy\n",
      "Serves: Serves 4\n",
      "Diet Type: Gluten-free\n",
      "Description: Impress with a glorious peach sundae for dessert at the end of a barbecue. Guaranteed to go down well, it’s really just an assembly of pleasing ingredients\n",
      "Ingredients: 415gcan peaches halves,in juice or light syrup, 200gfrozen raspberries, 4scoops vanilla ice cream(gluten-free, if necessary), 30gflaked almonds, 150mldouble cream\n",
      "Instructions: Drain the peaches, reserving the liquid, then char on thebarbecuefor 5-8 mins. Transfer to a flameproof pan or tray and set aside. Use a jug orhand blenderto purée the reserved liquid from the peaches and 130g of the frozen raspberries. Keep chilled until needed.Will keep chilled for a day. About 10 mins before serving, remove the ice cream from the freezer to soften slightly, and set the tray or pan of peaches over the still-warm barbecue for about 5 mins to warm through. If you like, toast the flaked almonds in a small, dry pan over a low heat. Whip the cream until it leaves a ribbon trail when the whisk is lifted out. Cut each warmed peach half into three pieces, then divide between bowls or coupes and top with a scoop of ice cream, 1-2 dessert spoons of the raspberry purée and an equal amount of whipped cream. Scatter over the rest of the berries and the flaked almonds. \n",
      "\n",
      "-----\n",
      "\n",
      "please a dessert recommendation\n"
     ]
    }
   ],
   "source": [
    "context_texts = [f\"Title: {c['title']}\\nPreparation Time: {c['prep_time']}\\nCooking Time: {c['cook_time']}\\nDifficulty: {c['difficulty']}\\nServes: {c['serves']}\\nDiet Type: {c['diet_type']}\\nDescription: {c['description']}\\nIngredients: {c['ingredients']}\\nInstructions: {c['instructions']} \" for c in contexts]\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(context_texts) + \"\\n\\n-----\\n\\n\" + query\n",
    "print(augmented_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
    "user questions based on the information provided by the user above\n",
    "each question. If the information can not be found in the information\n",
    "provided by the user you truthfully say \"I don't know\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mAnswer this question using the provided context only.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mContext:\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;132;01m{context}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, augmented_query)])\n\u001b[0;32m---> 15\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRunnablePassthrough\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m rag_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive me a recipe with chicken and spaghetti\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/recipes_rag/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:447\u001b[0m, in \u001b[0;36mRunnable.__ror__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    439\u001b[0m     other: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     ],\n\u001b[1;32m    445\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunnableSerializable[Other, Output]:\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compose this Runnable with another object to create a RunnableSequence.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/recipes_rag/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5518\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableLambda(cast(Callable[[Input], Output], thing))\n\u001b[1;32m   5517\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(thing, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m-> 5518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], \u001b[43mRunnableParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   5521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5522\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5523\u001b[0m     )\n",
      "File \u001b[0;32m~/recipes_rag/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3385\u001b[0m, in \u001b[0;36mRunnableParallel.__init__\u001b[0;34m(self, steps__, **kwargs)\u001b[0m\n\u001b[1;32m   3382\u001b[0m merged \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msteps__} \u001b[38;5;28;01mif\u001b[39;00m steps__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   3383\u001b[0m merged\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   3384\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m-> 3385\u001b[0m     steps__\u001b[38;5;241m=\u001b[39m{key: \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, r \u001b[38;5;129;01min\u001b[39;00m merged\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   3386\u001b[0m )\n",
      "File \u001b[0;32m~/recipes_rag/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5520\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableParallel(thing))\n\u001b[1;32m   5519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   5521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5522\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5523\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "{question}\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", augmented_query)])\n",
    "\n",
    "rag_chain = {\"context\": primer, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "\n",
    "response = rag_chain.invoke(\"give me a recipe with chicken and spaghetti\")\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "# res = llm.invoke(\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": primer},\n",
    "#         {\"role\": \"user\", \"content\": augmented_query}\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_content = res.choices[0].message.content\n",
    "display(Markdown(response_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Compare Response with Non-Augmented Query\n",
    "res_non_augmented = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_content = res.choices[0].message.content\n",
    "display(Markdown(response_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_recipes",
   "language": "python",
   "name": "venv_recipes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
